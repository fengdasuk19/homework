{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import module needed\n",
    "import copy\n",
    "import datetime\n",
    "import matplotlib.markers as plt_markers\n",
    "\n",
    "\n",
    "# define helper class\n",
    "class CoachTeam(object):\n",
    "    \n",
    "    def __init__(self, net, optimizer, loss_func, \n",
    "                 stage_names=['train', 'valid', 'test'], ind_names=['loss', 'acc']):\n",
    "        # net components\n",
    "        self.net_base = copy.deepcopy(net)\n",
    "        self.net = copy.deepcopy(self.net_base)\n",
    "        assert hasattr(self.net, 'name'), 'The nn object you want to use should have \\\n",
    "an attribute called `name`.'\n",
    "        self.optimizer = optimizer #(self.net.parameters()) #should init a new optimizer in each iteration\n",
    "        self.loss_func = loss_func\n",
    "\n",
    "        # storage\n",
    "        self.stage_names = stage_names\n",
    "        self.ind_names = ind_names\n",
    "        self.results = {ind:{stage:[] for stage in self.stage_names} for ind in self.ind_names}\n",
    "        \n",
    "    def pipeline_helper(self, n_iters, digit_rangesss, sum_epochs=15, interval_valid=50, dirname_prefix='outputs'):\n",
    "        # set dirname\n",
    "        self.dirname = dirname_prefix + '_' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "        if not os.path.isdir(self.dirname):\n",
    "            os.mkdir(self.dirname)\n",
    "        for i in range(n_iters):\n",
    "            # reset data for each experiment\n",
    "            self.net = copy.deepcopy(self.net_base)\n",
    "            self.results = {ind:{stage:[] for stage in self.stage_names} for ind in self.ind_names}\n",
    "            \n",
    "            # working pipeline\n",
    "            self.train_helper(self.net, self.loss_func, self.optimizer(self.net.parameters()), \n",
    "                              digit_rangesss, sum_epochs=sum_epochs, interval_valid=interval_valid)\n",
    "            self.test_helper(self.net)\n",
    "            self.save(mode='file', netname=self.net.name, suffix=str(i))\n",
    "            num_valid = sum_epochs * len(dataloader_train) // interval_valid\n",
    "            self.plot_single(self.net.name, plot_test=False, suffix=str(i), num_valid=num_valid)\n",
    "            self.plot_single(self.net.name, plot_test=True, suffix=str(i))\n",
    "            print('Round {}: OK'.format(i))\n",
    "        print('==================================================')\n",
    "        ############## SOME BUGS EXIST IN self.plot_whole #############################\n",
    "#         self.plot_whole(net.name, plot_test=False, plot_origin=True, plot_mean=True, num_valid=num_valid)\n",
    "#         self.plot_whole(net.name, plot_test=False, plot_origin=True, plot_mean=False, num_valid=num_valid)\n",
    "#         self.plot_whole(net.name, plot_test=False, plot_origin=False, plot_mean=True, num_valid=num_valid)\n",
    "#         self.plot_whole(net.name, plot_test=True, plot_origin=True, plot_mean=True)\n",
    "#         self.plot_whole(net.name, plot_test=True, plot_origin=True, plot_mean=False)\n",
    "#         self.plot_whole(net.name, plot_test=True, plot_origin=False, plot_mean=True)\n",
    "        print('Finish all the pipeline.')    \n",
    "        \n",
    "        \n",
    "    def train_helper(self, net, loss_func, optimizer, digit_rangesss, sum_epochs=15, interval_valid=50):\n",
    "        # train and validate, using digit_range sequences\n",
    "        for idx,digit_range in enumerate(digit_rangesss):\n",
    "            raw_out = {ind:[] for ind in self.ind_names}\n",
    "\n",
    "            raw_out['loss'], raw_out['acc'], self.n = train_net(\n",
    "                net=net, loss_func=loss_func, optimizer=optimizer, digit_range=digit_range,\n",
    "                sum_epochs=sum_epochs//len(digit_rangesss), interval_valid=interval_valid\n",
    "            )\n",
    "#             raw_out['loss'], raw_out['acc'], net = train_net(\n",
    "#                 net=net, loss_func=loss_func, optimizer=optimizer, digit_range=digit_range,\n",
    "#                 sum_epochs=sum_epochs//len(digit_rangesss), interval_valid=interval_valid\n",
    "#             )\n",
    "            \n",
    "            # save in RAM: train_data and valid_data \n",
    "            self.save(mode='dict-results', data=raw_out)\n",
    "            print('Save data(train & validation): OK in RAM, for', digit_range)\n",
    "        print('Train net: OK')\n",
    "        \n",
    "    def test_helper(self, net):\n",
    "        # test(evaluate)\n",
    "        net.eval()\n",
    "        \n",
    "        raw_out = {ind:{'test':[]} for ind in self.ind_names}\n",
    "        for kdx, batch_t in enumerate(dataloader_test):\n",
    "            xs_t, ys_t = batch_t\n",
    "            xs_t, ys_t = (xs_t.cuda(), ys_t.cuda()) if use_cuda else (xs_t, ys_t)\n",
    "            xs_t, ys_t = Variable(xs_t), Variable(ys_t)\n",
    "            preds_t = net(xs_t)\n",
    "            loss_test_raw = loss_func(preds_t, ys_t)\n",
    "            raw_out['loss']['test'].append(loss_test_raw.cpu().data.numpy() if use_cuda \\\n",
    "                                           else loss_test_raw.data.numpy())\n",
    "            raw_out['acc']['test'].append(evaludate_acc(preds_t, ys_t)[0])\n",
    "        \n",
    "        # save in RAM: test_data\n",
    "        self.save(mode='dict-results', data=raw_out, stages=['test'])\n",
    "        print('Save data(test): OK in RAM')\n",
    "        \n",
    "    def save(self, mode, data=None, netname=None, stages=['train', 'valid'], suffix=None):        \n",
    "        if 'dict-results' == mode:\n",
    "            assert data is not None, 'Your should specify the data you want to save in RAM.'\n",
    "            for ind in self.ind_names:\n",
    "                for stage in stages:\n",
    "                    items = [i[0] if isinstance(i, np.ndarray) else i for i in data[ind][stage]]\n",
    "                    if stage not in self.results[ind]:\n",
    "                        self.results[ind][stage] = copy.deepcopy(items)\n",
    "                    else:\n",
    "                        self.results[ind][stage].extend(items)\n",
    "        \n",
    "        if 'file' == mode:\n",
    "            assert netname is not None, 'You should specify the **NAME** of this neural network.'\n",
    "            \n",
    "            lacks = []\n",
    "            for stage in self.stage_names:\n",
    "                tmp_pd = {ind:copy.deepcopy(self.results[ind][stage]) for ind in self.ind_names}\n",
    "                tmp_pd = pd.DataFrame(data=tmp_pd, columns=self.ind_names)\n",
    "                if suffix:\n",
    "                    filename = os.path.join(os.getcwd(), self.dirname, \n",
    "                                            '{}-sheet-{}-{}.csv'.format(netname, stage, suffix))\n",
    "                else:\n",
    "                    filename = os.path.join(os.getcwd(), self.dirname, \n",
    "                                            '{}-sheet-{}.csv'.format(netname, stage))\n",
    "                    \n",
    "                # write to csv\n",
    "                if os.path.isfile(filename):\n",
    "                    pd_source = pd.read_csv(filename)\n",
    "                    tmp_pd = pd.concat([pd_source, tmp_pd])\n",
    "                    tmp_pd.to_csv(filename, index=False) \n",
    "                else:\n",
    "                    tmp_pd.to_csv(filename, index=False)\n",
    "                        \n",
    "                print('Save data in file OK:', filename)\n",
    "    \n",
    "    def plot_single(self, netname, suffix=None, plot_test=True, num_valid=None):        \n",
    "        if plot_test:\n",
    "            # plot: test\n",
    "            \n",
    "            x_inds = np.arange(len(dataloader_test))\n",
    "            fig, axes_raw = plt.subplots(1, len(self.ind_names), figsize=(15,5))\n",
    "            axes = {ind:axes_raw[i] for i,ind in enumerate(self.ind_names)}\n",
    "            for ind in self.ind_names:\n",
    "                axes[ind].plot(x_inds, self.results[ind]['test'], label='{}_test'.format(ind))\n",
    "                axes[ind].set_xlabel('num_iter')\n",
    "                axes[ind].set_ylabel(ind)\n",
    "            \n",
    "            if suffix:\n",
    "                filename = os.path.join(os.getcwd(), self.dirname, \n",
    "                                        '{}-curves_test-{}'.format(netname, suffix))\n",
    "            else:\n",
    "                filename = os.path.join(os.getcwd(), self.dirname, '{}-curves_test'.format(netname))\n",
    "                \n",
    "            plt.savefig(filename)\n",
    "            \n",
    "        if not plot_test:\n",
    "            # plot: train & validation\n",
    "            \n",
    "            fig, axes_raw = plt.subplots(1, len(self.ind_names), figsize=(15, 5))\n",
    "            axes = {self.ind_names[i]:ax for i,ax in enumerate(axes_raw) }\n",
    "            \n",
    "            assert num_valid is not None, 'You should specify how many times \\\n",
    "the validation process executed each round.'\n",
    "            x_inds = np.arange(num_valid)\n",
    "            for ind in ['loss', 'acc']:\n",
    "                for stage in ['train', 'valid']:\n",
    "                    axes[ind].plot(x_inds, self.results[ind][stage], label='{}_{}'.format(ind, stage))\n",
    "                \n",
    "                axes[ind].set_xlabel('num_iter')\n",
    "                axes[ind].set_ylabel(ind)\n",
    "                axes[ind].set_title('data on: convnet_0')\n",
    "                axes[ind].legend()\n",
    "            \n",
    "            plt.tight_layout(w_pad=10)\n",
    "            \n",
    "            if suffix:\n",
    "                filename = os.path.join(os.getcwd(), self.dirname, \n",
    "                                        '{}-curves-train_validation-{}'.format(netname, suffix))\n",
    "            else:\n",
    "                filename = os.path.join(os.getcwd(), self.dirname, '{}-curves-train_validation'.format(netname))\n",
    "                \n",
    "            plt.savefig(filename)\n",
    "\n",
    "            # # fig.show() \n",
    "            # comment the command above to avoid warning \n",
    "            #`UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure`\n",
    "            \n",
    "#################### SOME BUGS EXIST IN CODE BELOW ##############################################################\n",
    "#     def plot_whole(self, netname, num_valid, plot_test=False, plot_origin=True, plot_mean=False):\n",
    "#         empty_markers = ['None', None, ' ', '']\n",
    "#         plt_markers_list = list([mk for mk in plt_markers.MarkerStyle.markers.keys() if mk not in empty_markers])\n",
    "#         plt_markers_gen = (mk for mk in plt_markers_list)\n",
    "        \n",
    "#         fig, axes_raw = plt.subplots(1, 2, figsize=(15, 5))\n",
    "#         axes = {ind:axes_raw[i] for i,ind in enumerate(self.ind_names)}\n",
    "#         alpha_dict = {'train':0.7 ,'valid':1.0, 'test':1.0}\n",
    "\n",
    "#         ind_data = {}\n",
    "#         for ind in self.ind_names:\n",
    "#             for stage in stage_names:\n",
    "#                 k = '{}_{}-mean'.format(ind, stage)\n",
    "#                 ind_data[k] = []\n",
    "                \n",
    "#         if plot_test:\n",
    "#             x_inds = np.arange(len(dataloader_test))\n",
    "            \n",
    "#             for i in range(n_iters):\n",
    "#                 for stage in stage_names[-1:]:\n",
    "#                     filename = '{}-sheet-{}-{}.csv'.format(netname, stage, i)\n",
    "#                     filename = os.path.join(os.getcwd(), self.dirname, filename)\n",
    "#                     df = pd.read_csv(filename)\n",
    "#                     for ind in ind_names:\n",
    "#                         # save data for the mean curve\n",
    "#                         k = '{}_{}-mean'.format(ind, stage)\n",
    "#                         ind_data[k].append(df[ind].values)\n",
    "                        \n",
    "#                         # plot\n",
    "#                         if plot_origin:\n",
    "#                             axes[ind].plot(x_inds, df[ind], label='{}_{}-{}'.format(ind, stage, i), \n",
    "#                                            marker=next(plt_markers_gen), alpha=alpha_dict[stage])\n",
    "#             if plot_mean:\n",
    "#                 for ind in ind_names:\n",
    "#                     for stage in stage_names[-1:]:\n",
    "#                         k = '{}_{}-mean'.format(ind, stage)\n",
    "#                         ind_data[k] = np.array(ind_data[k]).mean(axis=0)\n",
    "#                         axes[ind].plot(x_inds, ind_data[k], label=k,\n",
    "#                                        marker=next(plt_markers_gen), alpha=alpha_dict[stage])\n",
    "        \n",
    "#             for ind in ind_names:    \n",
    "#                 axes[ind].legend()\n",
    "\n",
    "#             plt.tight_layout(w_pad=10)\n",
    "\n",
    "#             use_origin = 'Origin' if plot_origin else 'noOrigin'\n",
    "#             use_mean = 'Mean' if plot_origin else 'noMean'\n",
    "#             filename = '{}-curves-test-whole-{}{}'.format(netname, use_origin, use_mean)\n",
    "#             filename = os.path.join(os.getcwd(), self.dirname, filename)\n",
    "#             plt.savefig(filename)\n",
    "                \n",
    "#         if not plot_test:\n",
    "#             # plot: train_validation\n",
    "#             x_inds = np.arange(num_valid)\n",
    "            \n",
    "#             for i in range(n_iters):\n",
    "#                 for stage in stage_names[:-1]:\n",
    "#                     filename_base = '{}-sheet-{}-{}.csv'.format(netname, stage, i)\n",
    "#                     filename = os.path.join(os.getcwd(), self.dirname, filename_base)\n",
    "#                     assert os.path.isfile(filename), 'Lack file: '.format(filename_base)\n",
    "#                     df = pd.read_csv(filename)\n",
    "#                     for ind in self.ind_names:\n",
    "#                         # save data for the mean curve\n",
    "#                         k = '{}_{}-mean'.format(ind, stage)\n",
    "#                         ind_data[k].append(df[ind].values)\n",
    "        \n",
    "#                         # plot\n",
    "#                         if plot_origin:\n",
    "#                             axes[ind].plot(x_inds, df[ind], label='{}_{}-{}'.format(ind, stage, i), \n",
    "#                                            marker=next(plt_markers_gen), alpha=alpha_dict[stage])\n",
    "\n",
    "#             if plot_mean:\n",
    "#                 for ind in self.ind_names:\n",
    "#                     for stage in stage_names[:-1]:\n",
    "#                         k = '{}_{}-mean'.format(ind, stage)\n",
    "#                         ind_data[k] = np.array(ind_data[k]).mean(axis=0)\n",
    "#                         axes[ind].plot(x_inds, ind_data[k], label=k,\n",
    "#                                        marker=next(plt_markers_gen), alpha=alpha_dict[stage])\n",
    "\n",
    "#             for ind in self.ind_names:    \n",
    "#                 axes[ind].legend()\n",
    "            \n",
    "#             plt.tight_layout(w_pad=10)\n",
    "            \n",
    "#             use_origin = 'Origin' if plot_origin else 'noOrigin'\n",
    "#             use_mean = 'Mean' if plot_origin else 'noMean'\n",
    "#             filename = '{}-curves-train_validation-whole-{}{}'.format(netname, use_origin, use_mean)\n",
    "#             filename = os.path.join(os.getcwd(), self.dirname, filename)\n",
    "#             plt.savefig(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
